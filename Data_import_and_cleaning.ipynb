{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "267a9091-fe48-4d65-8161-46713944631e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Building a recommendation system with restaurants in London"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edab855-5c40-4130-827f-9c2d17fd2360",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Ideas\n",
    "\n",
    "#### < Maybe find a map dataset or something to get geo data for each restaurant, would be nice to have a cuisine datapoint too\n",
    "\n",
    "#### < NLP angle with the reviews textual data\n",
    "\n",
    "#### < Can use date as a factor, more recent the review, the more weighting it should have\n",
    "\n",
    "#### < What does good look like? Like what is a 'good' recommendation?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be1e438-287e-4edd-a892-078ceedf2d93",
   "metadata": {
    "tags": []
   },
   "source": [
    "_______________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97677010-f5d4-4a9e-8772-c8c09be67960",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Factor Release Plan\n",
    "\n",
    "#### Release 1\n",
    "\n",
    "##### 1. Initial recommender based on review value and volume\n",
    "##### 2. Involve date as a factor of review reliability\n",
    "##### 3. Introduce textual NLP analysis of reviews as another way of weighting\n",
    "##### 4. Bring in geo data for people to select areas or something?\n",
    "##### 5. Would be nice to webscrape cuisine as a datapoint too\n",
    "##### 6. Could also include author id as a factor - potentially someone who posts lots of reviews are more reliable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf05a414-5819-4a01-bc65-346cf24f5b89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "import dateutil.parser as parser\n",
    "from datetime import datetime, date, timedelta\n",
    "import torch\n",
    "import skorch\n",
    "import scipy\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import sys\n",
    "from skorch.helper import DataFrameTransformer\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, mean_squared_error, r2_score\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from skorch.callbacks import EarlyStopping\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skorch import NeuralNetRegressor\n",
    "import pickle\n",
    "import emoji\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a7eaaf-ccec-4ad0-a491-0bc32c5ff08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ndsna\\AppData\\Local\\Temp\\ipykernel_33376\\2783312507.py:1: DtypeWarning: Columns (0,1,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  initial_df = pd.read_csv('Data/London_reviews.csv')\n"
     ]
    }
   ],
   "source": [
    "initial_df = pd.read_csv('Data/London_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5106e42e-d2e5-4d6a-9043-cf6219fcb594",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Unnamed: 0 parse_count       restaurant_name rating_review    sample  \\\n",
      "0               0           1  Cocotte_Notting_Hill           5.0  Positive   \n",
      "1               1           2  Cocotte_Notting_Hill           5.0  Positive   \n",
      "2               2           3  Cocotte_Notting_Hill           5.0  Positive   \n",
      "3               3           4  Cocotte_Notting_Hill           5.0  Positive   \n",
      "4               4           5  Cocotte_Notting_Hill           5.0  Positive   \n",
      "...           ...         ...                   ...           ...       ...   \n",
      "996562     999995      999996       The_Old_Brewery           4.0  Positive   \n",
      "996563     999996      999997       The_Old_Brewery           2.0  Negative   \n",
      "996564     999997      999998       The_Old_Brewery           5.0  Positive   \n",
      "996565     999998      999999       The_Old_Brewery           5.0  Positive   \n",
      "996566     999999     1000000       The_Old_Brewery           3.0  Negative   \n",
      "\n",
      "               review_id                                       title_review  \\\n",
      "0       review_771556136                                       JUST PERFECT   \n",
      "1       review_771555883  Quality food, Food travels well, Excellent cus...   \n",
      "2       review_770716943                        Came here because we missed   \n",
      "3       review_770027676                                      Great service   \n",
      "4       review_766307138                 ð“”ð”ð“¬ð“®ð“µð“µð“®ð“·ð“½ ð“•ð“ªð“»ð“¶-ð“½ð“¸-ð“£ð“ªð“«ð“µð“® ð“¡ð“¸ð“½ð“²ð“¼ð“¼ð“®ð“»ð“²ð“®   \n",
      "...                  ...                                                ...   \n",
      "996562  review_665762822                                              Lunch   \n",
      "996563  review_664749502                                    Flat atmosphere   \n",
      "996564  review_663033085                          Lovely Motherâ€™s Day Lunch   \n",
      "996565  review_662538673                        Lovely relaxing lunch venue   \n",
      "996566  review_659900789                      Special was not that special    \n",
      "\n",
      "                                           review_preview  \\\n",
      "0       I was away for couple of months and  I am so h...   \n",
      "1       I recently ordered over the phone from Cocotte...   \n",
      "2       Came here because we missed our table at Farma...   \n",
      "3       My first time in cocotte and was amazed by how...   \n",
      "4       A healthy-homemade dishes using farm-grown ing...   \n",
      "...                                                   ...   \n",
      "996562  Popped in for a lunch time snack when visiting...   \n",
      "996563  Visited once before a couple of years previous...   \n",
      "996564  My husband and I had a wonderful lunch here on...   \n",
      "996565  Had a very enjoyable lunch here, catching up w...   \n",
      "996566  I have been to The Old Brewery under his previ...   \n",
      "\n",
      "                                              review_full                date  \\\n",
      "0       I was away for couple of months and I am so ha...  September 23, 2020   \n",
      "1       I recently ordered over the phone from Cocotte...  September 23, 2020   \n",
      "2       Came here because we missed our table at Farma...  September 17, 2020   \n",
      "3       My first time in cocotte and was amazed by how...  September 12, 2020   \n",
      "4       A healthy-homemade dishes using farm-grown ing...     August 22, 2020   \n",
      "...                                                   ...                 ...   \n",
      "996562  Popped in for a lunch time snack when visiting...      April 12, 2019   \n",
      "996563  Visited once before a couple of years previous...       April 8, 2019   \n",
      "996564  My husband and I had a wonderful lunch here on...       April 2, 2019   \n",
      "996565  Had a very enjoyable lunch here, catching up w...      March 31, 2019   \n",
      "996566  I have been to The Old Brewery under his previ...      March 20, 2019   \n",
      "\n",
      "                  city                                     url_restaurant  \\\n",
      "0       London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "1       London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "2       London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "3       London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "4       London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "...                ...                                                ...   \n",
      "996562  London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "996563  London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "996564  London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "996565  London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "996566  London_England  https://www.tripadvisor.com/Restaurant_Review-...   \n",
      "\n",
      "         author_id  \n",
      "0            UID_0  \n",
      "1            UID_1  \n",
      "2            UID_2  \n",
      "3            UID_3  \n",
      "4            UID_4  \n",
      "...            ...  \n",
      "996562  UID_211196  \n",
      "996563  UID_186355  \n",
      "996564  UID_502226  \n",
      "996565  UID_502227  \n",
      "996566  UID_502228  \n",
      "\n",
      "[996567 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "print(initial_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b94ac814-884d-4f70-95e7-f7633edabd29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dropping some unwanted columns from the initial dataset\n",
    "df = initial_df.drop(['Unnamed: 0','parse_count'],axis=1)\n",
    "\n",
    "# making a new name column which removes the underscores\n",
    "df['restaurant_name_clean'] = [(str(s).replace('_', ' ')) for s in df['restaurant_name']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38115f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gmaps1 = pd.read_csv('Data/Restaurant_Location_Details.csv')\n",
    "gmaps1 = gmaps1.drop_duplicates(keep='first')\n",
    "\n",
    "gmaps2 = pd.read_csv(('Data/Restaurant_Location_Additional_Details.csv'))\n",
    "gmaps2 = gmaps2.drop_duplicates(keep='first')\n",
    "\n",
    "gmapsdata = gmaps2.merge(gmaps1, how='left', on='place_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "654ea867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merging the main Tripadvisor dataset with the new Google Maps data sourced from the API scripts\n",
    "\n",
    "# as some of the restaurant names in the Tripadvisor dataset are slightly different to as recorded \n",
    "# on Google Maps (an example is \"Genzo Greek\" in Tripadvisor is \"GENZO\" on Google Maps), we will need to \n",
    "# perform some fuzzy matching between the two datasets in order to merge them.\n",
    "import difflib\n",
    "\n",
    "# gmapsdata['fuzzy_name'] = gmapsdata['name'].apply(lambda x: difflib.get_close_matches(x, df['restaurant_name_clean'].unique(), n=1)[0])\n",
    "\n",
    "from fuzzywuzzy import process\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "# following function adapted from the below link:\n",
    "# https://stackoverflow.com/questions/13636848/is-it-possible-to-do-fuzzy-match-merge-with-python-pandas\n",
    "def fuzzy_merge(df_1, df_2, key1, key2, threshold=95, limit=1):\n",
    "    \"\"\"\n",
    "    :param df_1: the left table to join\n",
    "    :param df_2: the right table to join\n",
    "    :param key1: key column of the left table\n",
    "    :param key2: key column of the right table\n",
    "    :param threshold: how close the matches should be to return a match, based on Levenshtein distance\n",
    "    :param limit: the amount of matches that will get returned, these are sorted high to low\n",
    "    :return: dataframe with boths keys and matches\n",
    "    \"\"\"\n",
    "    s = df_2[key2].tolist()\n",
    "    \n",
    "    m = df_1.apply(lambda x: process.extract(x, s, limit=limit))    \n",
    "    df_1['matches'] = m\n",
    "    \n",
    "    m2 = df_1['matches'].apply(lambda x: ', '.join([i[0] for i in x if i[1] >= threshold]))\n",
    "    df_1['matches'] = m2\n",
    "    \n",
    "    return df_1\n",
    "\n",
    "dfnames = pd.Series(df['restaurant_name_clean'].unique())\n",
    "merged = fuzzy_merge(dfnames, gmapsdata, 'restaurant_name_clean', 'name', threshold=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96ab5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_names = merged.iloc[1834]\n",
    "TA_names = merged.iloc[0:1834]\n",
    "\n",
    "merged_names = pd.concat([TA_names, GM_names], axis=1, join='outer')\n",
    "merged_names = merged_names.rename(columns={0: \"Tripadvisor\", 1: \"Gmaps\"})\n",
    "\n",
    "merged_names.to_csv('Merged_Names2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a76c27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.merge(merged_names, left_on='restaurant_name_clean', right_on='Tripadvisor')\n",
    "df_merged = df2.merge(gmapsdata, left_on='Gmaps', right_on='name', how='left')\n",
    "test = df2.merge(gmapsdata, left_on='Gmaps', right_on='name', how='inner')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
